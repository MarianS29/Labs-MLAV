{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "004e5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets,ensemble,metrics\n",
    "import pdb\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MNIST_train():\n",
    "    \n",
    "    mnist_train_data = np.zeros([60000,784]) # fiecare linie este o img 28x28\n",
    "    mnist_train_labels = np.zeros(60000)\n",
    "    \n",
    "    # ~ url = 'https://github.com/golbin/TensorFlow-MNIST/tree/master/mnist/data/train-images-idx3-ubyte.gz'\n",
    "    # ~ r = requests.get(url, allow_redirects=True)\n",
    "    # ~ open('train-images-idx3-ubyte.gz', 'wb').write(r.content)\n",
    "    \n",
    "    # ~ url = 'https://github.com/golbin/TensorFlow-MNIST/tree/master/mnist/datatrain-images-idx3-ubyte.gz'\n",
    "    # ~ r = requests.get(url, allow_redirects=True)\n",
    "    # ~ open('train-labels.idx1-ubyte.gz', 'wb').write(r.content)\n",
    "    \n",
    "    f = open('train-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    g = open('train-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4 bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_train_data = np.fromfile(f,dtype=np.uint8).reshape(60000,28,28)\n",
    "    mnist_train_labels = np.fromfile(g,dtype=np.uint8)\n",
    "        \n",
    "    # Conversii pentru a se potrivi cu procesul de antrenare    \n",
    "    mnist_train_data = mnist_train_data.astype(np.float32)\n",
    "    mnist_train_labels = mnist_train_labels.astype(np.int64)\n",
    "        \n",
    "    return mnist_train_data, mnist_train_labels\n",
    "\n",
    "def get_MNIST_test():\n",
    "    \n",
    "    mnist_test_data = np.zeros([10000,784])\n",
    "    mnist_test_labels = np.zeros(10000)\n",
    "    \n",
    "    f = open('t10k-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    g = open('t10k-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4 bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_test_data = np.fromfile(f,dtype=np.uint8).reshape(10000,784)\n",
    "    mnist_test_labels = np.fromfile(g,dtype=np.uint8)\n",
    "    \n",
    "    # Conversii pentru a se potrivi cu procesul de testare    \n",
    "    mnist_test_data = mnist_test_data.astype(np.float32)\n",
    "    mnist_test_labels = mnist_test_labels.astype(np.int64)        \n",
    "    \n",
    "    return mnist_test_data, mnist_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9f0103ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        mnist_train_data,mnist_train_labels = get_MNIST_train()\n",
    "\n",
    "        self.data = mnist_train_data[:200]\n",
    "        self.labels = mnist_train_labels[:200]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_point = torch.from_numpy(self.data[index, ...])\n",
    "        label_point = torch.from_numpy(self.labels[index, ...])\n",
    "\n",
    "        return {'data': data_point, 'label': label_point}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5bdc8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class ReteaMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        # self.drop_x = nn.Dropout(p=0.5)\n",
    "        self.bn_x = nn.BatchNorm1d(num_features = 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.drop_x(x)\n",
    "        x = self.bn_x(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    " \n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "19d103cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mnistdataset = DatasetMNIST()\n",
    " \n",
    "mnist_loader = DataLoader(mnistdataset, batch_size=128, shuffle=True, num_workers=0)\n",
    " \n",
    "simple_CNN = ReteaMLP()\n",
    " \n",
    "loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    " \n",
    "optim = torch.optim.SGD(simple_CNN.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3658ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea la epoca 1 este 7.000000000000001%\n",
      "Acuratetea la epoca 2 este 18.5%\n",
      "Acuratetea la epoca 3 este 33.5%\n",
      "Acuratetea la epoca 4 este 46.0%\n",
      "Acuratetea la epoca 5 este 54.50000000000001%\n",
      "Acuratetea la epoca 6 este 65.0%\n",
      "Acuratetea la epoca 7 este 74.0%\n",
      "Acuratetea la epoca 8 este 77.5%\n",
      "Acuratetea la epoca 9 este 81.5%\n",
      "Acuratetea la epoca 10 este 83.5%\n",
      "Acuratetea la epoca 11 este 86.0%\n",
      "Acuratetea la epoca 12 este 87.0%\n",
      "Acuratetea la epoca 13 este 88.0%\n",
      "Acuratetea la epoca 14 este 88.5%\n",
      "Acuratetea la epoca 15 este 89.0%\n",
      "Acuratetea la epoca 16 este 90.5%\n",
      "Acuratetea la epoca 17 este 91.0%\n",
      "Acuratetea la epoca 18 este 91.0%\n",
      "Acuratetea la epoca 19 este 91.0%\n",
      "Acuratetea la epoca 20 este 92.5%\n",
      "Acuratetea la epoca 21 este 92.0%\n",
      "Acuratetea la epoca 22 este 91.5%\n",
      "Acuratetea la epoca 23 este 91.5%\n",
      "Acuratetea la epoca 24 este 93.0%\n",
      "Acuratetea la epoca 25 este 93.0%\n",
      "Acuratetea la epoca 26 este 94.0%\n",
      "Acuratetea la epoca 27 este 93.5%\n",
      "Acuratetea la epoca 28 este 92.5%\n",
      "Acuratetea la epoca 29 este 94.0%\n",
      "Acuratetea la epoca 30 este 93.5%\n",
      "Acuratetea la epoca 31 este 94.5%\n",
      "Acuratetea la epoca 32 este 94.5%\n",
      "Acuratetea la epoca 33 este 95.5%\n",
      "Acuratetea la epoca 34 este 95.0%\n",
      "Acuratetea la epoca 35 este 95.5%\n",
      "Acuratetea la epoca 36 este 94.5%\n",
      "Acuratetea la epoca 37 este 95.5%\n",
      "Acuratetea la epoca 38 este 95.5%\n",
      "Acuratetea la epoca 39 este 95.0%\n",
      "Acuratetea la epoca 40 este 96.0%\n"
     ]
    }
   ],
   "source": [
    "# Bucla de invatare\n",
    "     \n",
    "for ep in range(40):\n",
    " \n",
    "    predictii = []\n",
    "    etichete = []\n",
    " \n",
    "    for batch in mnist_loader:\n",
    "        data, label = batch['data'], batch['label']\n",
    " \n",
    "        current_predict = simple_CNN.forward(data)\n",
    " \n",
    "        loss = loss_function(current_predict, label)\n",
    " \n",
    "        current_predict = np.argmax(current_predict.detach().numpy(), axis=1)\n",
    " \n",
    "        predictii = np.concatenate((predictii,current_predict))\n",
    "        etichete = np.concatenate((etichete,label))\n",
    " \n",
    "        optim.zero_grad()\n",
    " \n",
    "        loss.backward()\n",
    " \n",
    "        optim.step()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optim, step_size = 20, gamma=0.1)\n",
    " \n",
    "    acc = np.sum(predictii==etichete)/len(predictii)\n",
    "    print( 'Acuratetea la epoca {} este {}%'.format(ep+1,acc*100) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "495fd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        mnist_train_data,mnist_train_labels = get_MNIST_train()\n",
    "\n",
    "        self.data = mnist_train_data[:200]\n",
    "        self.labels = mnist_train_labels[:200]\n",
    "\n",
    "        self.transf = transforms.Compose([\n",
    "            transforms.ToPILImage(), transforms.Resize([224,224]),\n",
    "            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_point = torch.from_numpy(self.data[index, ...])\n",
    "        label_point = torch.from_numpy(self.labels[index, ...])\n",
    "\n",
    "        data_point = np.tile(data_point[..., None], (1,1,3))\n",
    "\n",
    "        data_point = self.transf(data_point)\n",
    "\n",
    "        label_point = torch.tensor(label_point,dtype=torch.long)\n",
    "\n",
    "        return {'data': data_point, 'label': label_point}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "66b0d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "cnn = models.alexnet(pretrained=True)\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d350684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cnn.features.parameters():\n",
    "    param.requires_grad = False # nu se mai actualizeaza ponderile\n",
    "\n",
    "cnn.classifier[6] = nn.Linear(4096,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e4b603e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_17568\\2467148101.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_point = torch.tensor(label_point,dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea la epoca 1 este 14.499999999999998%\n",
      "Acuratetea la epoca 2 este 13.0%\n",
      "Acuratetea la epoca 3 este 19.0%\n",
      "Acuratetea la epoca 4 este 28.000000000000004%\n",
      "Acuratetea la epoca 5 este 35.5%\n",
      "Acuratetea la epoca 6 este 30.0%\n",
      "Acuratetea la epoca 7 este 31.5%\n",
      "Acuratetea la epoca 8 este 33.0%\n",
      "Acuratetea la epoca 9 este 29.5%\n",
      "Acuratetea la epoca 10 este 31.0%\n",
      "Acuratetea la epoca 11 este 32.5%\n",
      "Acuratetea la epoca 12 este 34.5%\n",
      "Acuratetea la epoca 13 este 32.5%\n",
      "Acuratetea la epoca 14 este 36.5%\n",
      "Acuratetea la epoca 15 este 36.0%\n",
      "Acuratetea la epoca 16 este 35.0%\n",
      "Acuratetea la epoca 17 este 40.0%\n",
      "Acuratetea la epoca 18 este 36.5%\n",
      "Acuratetea la epoca 19 este 43.0%\n",
      "Acuratetea la epoca 20 este 44.5%\n",
      "Acuratetea la epoca 21 este 41.0%\n",
      "Acuratetea la epoca 22 este 45.0%\n",
      "Acuratetea la epoca 23 este 44.5%\n",
      "Acuratetea la epoca 24 este 46.0%\n",
      "Acuratetea la epoca 25 este 45.0%\n",
      "Acuratetea la epoca 26 este 42.0%\n",
      "Acuratetea la epoca 27 este 46.0%\n",
      "Acuratetea la epoca 28 este 47.0%\n",
      "Acuratetea la epoca 29 este 46.5%\n",
      "Acuratetea la epoca 30 este 44.5%\n",
      "Acuratetea la epoca 31 este 47.5%\n",
      "Acuratetea la epoca 32 este 43.5%\n",
      "Acuratetea la epoca 33 este 46.0%\n",
      "Acuratetea la epoca 34 este 45.5%\n",
      "Acuratetea la epoca 35 este 48.0%\n",
      "Acuratetea la epoca 36 este 50.0%\n",
      "Acuratetea la epoca 37 este 47.5%\n",
      "Acuratetea la epoca 38 este 55.00000000000001%\n",
      "Acuratetea la epoca 39 este 46.5%\n",
      "Acuratetea la epoca 40 este 50.0%\n"
     ]
    }
   ],
   "source": [
    "mnistdataset = DatasetMNIST()\n",
    "\n",
    "mnist_loader = DataLoader(mnistdataset, batch_size=128, shuffle=True, num_workers=0)\n",
    " \n",
    "simple_CNN = cnn\n",
    " \n",
    "loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    " \n",
    "optim = torch.optim.SGD(simple_CNN.parameters(), lr=1e-4)\n",
    "\n",
    "# Bucla de invatare\n",
    "     \n",
    "for ep in range(40):\n",
    " \n",
    "    predictii = []\n",
    "    etichete = []\n",
    " \n",
    "    for batch in mnist_loader:\n",
    "        data, label = batch['data'], batch['label']\n",
    " \n",
    "        current_predict = simple_CNN.forward(data)\n",
    " \n",
    "        loss = loss_function(current_predict, label)\n",
    " \n",
    "        current_predict = np.argmax(current_predict.detach().numpy(), axis=1)\n",
    " \n",
    "        predictii = np.concatenate((predictii,current_predict))\n",
    "        etichete = np.concatenate((etichete,label))\n",
    " \n",
    "        optim.zero_grad()\n",
    " \n",
    "        loss.backward()\n",
    " \n",
    "        optim.step()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optim, step_size = 20, gamma=0.1)\n",
    " \n",
    "    acc = np.sum(predictii==etichete)/len(predictii)\n",
    "    print( 'Acuratetea la epoca {} este {}%'.format(ep+1,acc*100) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
