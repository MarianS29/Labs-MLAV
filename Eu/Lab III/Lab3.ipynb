{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7563c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Nu trebuie tf pentru citirea datelor, dar trebuie pentru tot restul\n",
    "import torch \n",
    "def get_MNIST_train():\n",
    "    \n",
    "    mnist_train_data = np.zeros([60000,784])\n",
    "    mnist_train_labels = np.zeros(60000)\n",
    "    \n",
    "    f = open('train-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    g = open('train-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_train_data = np.fromfile(f,dtype=np.uint8).reshape(60000,784)\n",
    "    mnist_train_data = mnist_train_data.reshape(60000,1,28,28)\n",
    "    mnist_train_labels = np.fromfile(g,dtype=np.uint8)\n",
    "    \n",
    "    # Conversii pentru a se potrivi cu procesul de antrenare    \n",
    "    mnist_train_data = mnist_train_data.astype(np.float32)\n",
    "    mnist_train_labels = mnist_train_labels.astype(np.int64)\n",
    "    \n",
    "    return mnist_train_data, mnist_train_labels\n",
    "\n",
    "def get_MNIST_test():\n",
    "    \n",
    "    mnist_test_data = np.zeros([10000,784])\n",
    "    mnist_test_labels = np.zeros(10000)\n",
    "    \n",
    "    f = open('t10k-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    g = open('t10k-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_test_data = np.fromfile(f,dtype=np.uint8).reshape(10000,784)\n",
    "    mnist_test_data = mnist_test_data.reshape(10000,1,28,28)\n",
    "    mnist_test_labels = np.fromfile(g,dtype=np.uint8)\n",
    "        \n",
    "    # Conversii pentru a se potrivi cu procesul de antrenare    \n",
    "    mnist_test_data = mnist_test_data.astype(np.float32)\n",
    "    mnist_test_labels = mnist_test_labels.astype(np.int64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf323362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Retea_MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, nr_neuroni_input, nr_neuroni_hidden, nr_clase):\n",
    "        \n",
    "        # Pentru a putea folosi mai departe reteaua, este recomandata mostenirea\n",
    "        # clasei de baza nn.Module\n",
    "        super(Retea_MLP,self).__init__()\n",
    "        \n",
    "        # Definirea ponderilor si a deplasamentelor din stratul ascuns\n",
    "        self.w_h = torch.randn(nr_neuroni_input, nr_neuroni_hidden, dtype = torch.float, requires_grad=True)\n",
    "        self.b_h = torch.randn(nr_neuroni_hidden, dtype = torch.float, requires_grad=True)\n",
    "        \n",
    "        # Definirea ponderilor si a deplasamentelor din stratul de iesire\n",
    "        self.w_o = torch.randn(nr_neuroni_hidden, nr_clase, dtype = torch.float, requires_grad=True)\n",
    "        self.b_o = torch.randn(nr_clase, dtype = torch.float, requires_grad=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    \n",
    "    # Se aduna toate variabilele antrenabile intr-o lista, pentru a putea face referire rapida la ele\n",
    "    def parameters(self):\n",
    "        return [self.w_h, self.b_h, self.w_o, self.b_o]\n",
    "    \n",
    "    def forward(self,input_batch):\n",
    "        # Intr-un MLP, intrarea este sub forma unui vector, deci un batch\n",
    "        # este o matrice de dimensiunea nr_esantioane_batch x dimensiune esantion\n",
    "        input_batch = torch.from_numpy(input_batch)\n",
    "        self.hidden = torch.mm(input_batch, self.w_h) + self.b_h\n",
    "\n",
    "        self.hidden = self.relu(self.hidden)\n",
    "        \n",
    "        out = torch.mm(self.hidden, self.w_o) + self.b_o\n",
    "\n",
    "        # out = softmax(out) - se poate si fara (softmax este inclus in CrossEntropyLoss)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17eeddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retea_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Definirea straturilor CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Definirea stratului fully connected\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Definirea propagarii forward\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flattening\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021570c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea la epoca 1 este 92.04833333333333%\n",
      "Acuratetea la epoca 2 este 97.07666666666667%\n",
      "Acuratetea la epoca 3 este 97.82166666666666%\n",
      "Acuratetea la epoca 4 este 98.22166666666666%\n",
      "Acuratetea la epoca 5 este 98.50666666666666%\n",
      "Acuratetea la epoca 6 este 98.68333333333334%\n",
      "Acuratetea la epoca 7 este 98.80333333333333%\n",
      "Acuratetea la epoca 8 este 99.00666666666666%\n",
      "Acuratetea la epoca 9 este 99.12166666666667%\n",
      "Acuratetea la epoca 10 este 99.16%\n",
      "Acuratetea la epoca 11 este 99.26166666666667%\n",
      "Acuratetea la epoca 12 este 99.31333333333333%\n",
      "Acuratetea la epoca 13 este 99.385%\n",
      "Acuratetea la epoca 14 este 99.47333333333333%\n",
      "Acuratetea la epoca 15 este 99.49166666666667%\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def get_MNIST_train():\n",
    "    \n",
    "    mnist_train_data = np.zeros([60000,784])\n",
    "    mnist_train_labels = np.zeros(60000)\n",
    "    \n",
    "    f = open('train-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    g = open('train-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_train_data = np.fromfile(f,dtype=np.uint8).reshape(60000,784)\n",
    "    mnist_train_data = mnist_train_data.reshape(60000,1,28,28)\n",
    "    mnist_train_labels = np.fromfile(g,dtype=np.uint8)\n",
    "    \n",
    "    # Conversii pentru a se potrivi cu procesul de antrenare    \n",
    "    mnist_train_data = mnist_train_data.astype(np.float32)\n",
    "    mnist_train_labels = mnist_train_labels.astype(np.int64)\n",
    "    \n",
    "    return mnist_train_data, mnist_train_labels\n",
    "\n",
    "def get_MNIST_test():\n",
    "    \n",
    "    mnist_test_data = np.zeros([10000,784])\n",
    "    mnist_test_labels = np.zeros(10000)\n",
    "    \n",
    "    f = open('t10k-images.idx3-ubyte','r',encoding = 'latin-1')\n",
    "    g = open('t10k-labels.idx1-ubyte','r',encoding = 'latin-1')\n",
    "    \n",
    "    byte = f.read(16) #4 bytes magic number, 4 bytes nr imag, 4 bytes nr linii, 4 bytes nr coloane\n",
    "    byte_label = g.read(8) #4bytes magic number, 4 bytes nr labels\n",
    "    \n",
    "    mnist_test_data = np.fromfile(f,dtype=np.uint8).reshape(10000,784)\n",
    "    mnist_test_data = mnist_test_data.reshape(10000,1,28,28)\n",
    "    mnist_test_labels = np.fromfile(g,dtype=np.uint8)\n",
    "        \n",
    "    # Conversii pentru a se potrivi cu procesul de antrenare    \n",
    "    mnist_test_data = mnist_test_data.astype(np.float32)\n",
    "    mnist_test_labels = mnist_test_labels.astype(np.int64)\n",
    "    \n",
    "    return mnist_test_data, mnist_test_labels\n",
    "\n",
    "\n",
    "\n",
    "class DatasetMNIST(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        mnist_train_data,mnist_train_labels = get_MNIST_train()\n",
    "\n",
    "        self.data = mnist_train_data\n",
    "        self.labels = mnist_train_labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_point = self.data[index, ...]\n",
    "        label_point = self.labels[index, ...]\n",
    "\n",
    "        return {'data': data_point, 'label': label_point}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "mnistdataset = DatasetMNIST()\n",
    "\n",
    "mnistdataloader = DataLoader(mnistdataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "simple_CNN = Retea_CNN().to(\"cuda\")\n",
    "\n",
    "optim = torch.optim.SGD(simple_CNN.parameters(), lr=1e-5)\n",
    "\n",
    "for ep in range(15):\n",
    "\n",
    "    predictii = []\n",
    "    etichete = []\n",
    "\n",
    "    for batch in mnistdataloader:\n",
    "        data = batch['data'].to(\"cuda\")\n",
    "        label = batch['label'].to(\"cuda\")\n",
    "\n",
    "        # print(data.shape)\n",
    "        # print(label.shape)\n",
    "\n",
    "        # data_as_image = data[0, ...].cpu().detach().numpy().squeeze()\n",
    "        # print(data_as_image.shape)\n",
    "\n",
    "        # plt.imshow(data_as_image, cmap='gray')\n",
    "        # continue\n",
    "\n",
    "        current_predict = simple_CNN.forward(data)\n",
    "\n",
    "        # Se calculeaza valoarea momentana a functiei loss\n",
    "        loss = loss_function(current_predict, label) \n",
    "        \n",
    "        # Se memoreaza predictiile si etichetele aferente batch-ului actual (pentru calculul acuratetii)\n",
    "        current_predict = np.argmax(current_predict.cpu().detach().numpy(), axis=1)\n",
    "        label = label.cpu().detach().numpy()\n",
    "\n",
    "        predictii = np.concatenate((predictii,current_predict))\n",
    "        etichete = np.concatenate((etichete,label))\n",
    "\n",
    "        optim.zero_grad()\n",
    "            # 2. Calculul tuturor gradientilor. Backpropagation\n",
    "        loss.backward()\n",
    "            # 3. Actualizarea tuturor ponderilor, pe baza gradientilor.\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    # Calculam acuratetea\n",
    "    acc = np.sum(predictii==etichete)/len(predictii)\n",
    "    print( 'Acuratetea la epoca {} este {}%'.format(ep+1,acc*100) )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
